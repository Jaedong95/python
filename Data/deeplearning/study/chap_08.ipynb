{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89cec604",
   "metadata": {},
   "source": [
    "### Kaggle에서 다운 받은 데이터 구조 변경 (data_setup.py)\n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52fb72b1",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccf616a5",
   "metadata": {},
   "source": [
    "def make_dir(dir):\n",
    "    try:\n",
    "        os.stat(dir)\n",
    "    except:\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93d2a75f",
   "metadata": {},
   "source": [
    "def setup_dirs(dest_dir, train_dir, val_dir, test_dir):\n",
    "    make_dir(dest_dir)  # data\n",
    "    for folder in [train_dir, val_dir, test_dir]:\n",
    "        make_dir(Path(dest_dir + folder))  # data/test\n",
    "        _ = [make_dir(Path(dest_dir + folder + x)) for x in [\"cat\", \"dog\"]]  # creates cat and dog directories under folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68d4bd11",
   "metadata": {},
   "source": [
    "def copy_data(train_range, val_range, test_range, source_dir, dest_dir, train_dir, val_dir, test_dir):\n",
    "    for a in [\"cat\", \"dog\"]:\n",
    "        ranges = [ train_range, val_range, test_range]\n",
    "        folders = [train_dir, val_dir, test_dir]\n",
    "        for r, f in zip(ranges, folders):\n",
    "            for i in r:\n",
    "                src = Path(source_dir + a + \".\" + str(i) + \".jpg\")\n",
    "                dst = Path(dest_dir + f + a + \"/\" + a + \".\" + str(i) + \".jpg\")\n",
    "                shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "683a13d6",
   "metadata": {},
   "source": [
    "dest_dir = \"data/\"\n",
    "source_dir = \"train/\"\n",
    "\n",
    "# append these directories to /data\n",
    "test_dir = \"test/\"\n",
    "val_dir = \"val/\"\n",
    "train_dir = \"train/\"\n",
    "    \n",
    "# test and val will be 10%\n",
    "test_range = range(11249, 12500)  \n",
    "val_range = range(10000, 11250)\n",
    "train_range = range(0, 10000)\n",
    "\n",
    "setup_dirs(dest_dir, train_dir, val_dir, test_dir)\n",
    "copy_data(train_range, val_range, test_range, source_dir, dest_dir, train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61174926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce327f",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780c06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f44cb",
   "metadata": {},
   "source": [
    "### 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b3eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_feature_extraction():\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1165d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_fine_tuning(model, learning_rate=0.0001, momentum=0.9):\n",
    "    for layer in model.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in model.layers[249:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model.compile(optimizer=SGD(lr=learning_rate, momentum=momentum), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a84559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(name):\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tb_log\", name), write_graph=True, write_grads=False)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n",
    "                                          verbose=0, save_best_only=True)\n",
    "    return [tensorboard_callback, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bf976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data(train_data_dir, val_data_dir, img_width=299, img_height=299, batch_size=16):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed91e64",
   "metadata": {},
   "source": [
    "### 기본 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa4fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 26s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/train/\"\n",
    "val_dir = \"data/val/\"\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "train_generator, val_generator = setup_data(data_dir, val_dir)\n",
    "callbacks_fe = create_callbacks(name='feature_extraction')\n",
    "callbacks_ft = create_callbacks(name='fine_tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ceac3b",
   "metadata": {},
   "source": [
    "### 모델 훈련 (특징 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed797c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_feature_extraction()\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.n // batch_size,\n",
    "    callbacks=callbacks_fe,\n",
    "    verbose=1)\n",
    "\n",
    "scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "print(\"Step 1 Scores: Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c883c23",
   "metadata": {},
   "source": [
    "### 모델 훈련 (미세 조정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78953591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_fine_tuning(model)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.n // batch_size,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=2)\n",
    "\n",
    "scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "print(\"Step 2 Scores: Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
