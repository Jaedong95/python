{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f18fa1e5",
   "metadata": {},
   "source": [
    "''' 이진 분류 문제 풀기 '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561af9e",
   "metadata": {},
   "source": [
    "### 경고 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7751f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8797f81",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e53598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eadc1c3",
   "metadata": {},
   "source": [
    "### 경로 설정 및 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e81d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = './data/chapter_4/train/train_data.csv'\n",
    "VAL_DATA = './data/chapter_4/val/val_data.csv'\n",
    "TEST_DATA = './data/chapter_4/test/test_data.csv'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4dd6f29",
   "metadata": {},
   "source": [
    "!mkdir ./ch4_tb_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f351ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수 \n",
    "def load_data():\n",
    "    train = pd.read_csv(TRAIN_DATA)\n",
    "    val = pd.read_csv(VAL_DATA)\n",
    "    test = pd.read_csv(TEST_DATA)\n",
    "    \n",
    "    data = dict()\n",
    "    data['train_y'] = train.pop('y')\n",
    "    data['val_y'] = val.pop('y')\n",
    "    data['test_y'] = test.pop('y')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    val = scaler.transform(val)\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    data['train_X'] = train\n",
    "    data['val_X'] = val\n",
    "    data['test_X'] = test\n",
    "    \n",
    "    # scaler를 유지함으로써 예측을 다시 원래 크기로 복원할 수 있도록 함 \n",
    "    data['scaler'] = scaler \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8e3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56e9156d",
   "metadata": {},
   "source": [
    "def create_callbacks():\n",
    "    tensorboard_callback = TensorBoard(log_dir='./ch4_tb_log/mlp', histogram_freq=1, batch_size=32, \n",
    "                                        write_graph=True, write_grads=False)\n",
    "    return [tensorboard_callback]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79846c43",
   "metadata": {},
   "source": [
    "callbacks = create_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c92ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 함수 \n",
    "def build_network(input_features=None):\n",
    "    inputs = Input(shape=(input_features, ), name='input')\n",
    "    x = Dense(128, activation='relu', name='hidden1')(inputs)\n",
    "    x = Dense(64, activation='relu', name='hidden2')(x)\n",
    "    x = Dense(32, activation='relu', name='hidden3')(x)\n",
    "    x = Dense(16, activation='relu', name='hidden4')(x)\n",
    "    x = Dense(8, activation='relu', name='hidden5')(x)\n",
    "    prediction = Dense(1, activation='sigmoid', name='final')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00b87cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9200, 178)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_X'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6035d",
   "metadata": {},
   "source": [
    "### ROC AUC 사용자 지정 콜백 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da843dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAUCScore(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        super(RocAUCScore, self).__init__()\n",
    "        \n",
    "    # 각 epoch 말에 ROC AUC 점수 계산 \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\n *** ROC AUC Score: %s - roc-auc_val: %s ***' % (str(roc), str(roc_val)))\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b67f92",
   "metadata": {},
   "source": [
    "### Callback 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cac28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(data):\n",
    "    tensorboard_callback = TensorBoard(log_dir='./ch4_tb_log/mlp', histogram_freq=1, batch_size=32, \n",
    "                                        write_graph=True, write_grads=False)\n",
    "    roc_auc_callback = RocAUCScore(\n",
    "        training_data=(data['train_X'], data['train_y']),\n",
    "        validation_data=(data['val_X'], data['val_y']))\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath='./model-weights.{epoch:02d}-{val_acc:.6f}.hdf5',\n",
    "        monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "    return [tensorboard_callback, roc_auc_callback, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0581ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1191b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9200, 178)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd1ad2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1150, 178), (1150,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['val_X'].shape, data['val_y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e07689",
   "metadata": {},
   "source": [
    "### 모델 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c98d04d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 9200 samples, validate on 1150 samples\n",
      "Epoch 1/20\n",
      "8448/9200 [==========================>...] - ETA: 0s - loss: 0.2450 - acc: 0.9357\n",
      " *** ROC AUC Score: 0.990110281851847 - roc-auc_val: 0.9911686695215375 ***\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95913, saving model to ./model-weights.01-0.959130.hdf5\n",
      "9200/9200 [==============================] - 1s 150us/sample - loss: 0.2342 - acc: 0.9383 - val_loss: 0.1280 - val_acc: 0.9591\n",
      "Epoch 2/20\n",
      "8704/9200 [===========================>..] - ETA: 0s - loss: 0.0822 - acc: 0.9731\n",
      " *** ROC AUC Score: 0.9975708696101282 - roc-auc_val: 0.9932085685638221 ***\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95913 to 0.98000, saving model to ./model-weights.02-0.980000.hdf5\n",
      "9200/9200 [==============================] - 1s 131us/sample - loss: 0.0817 - acc: 0.9733 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 3/20\n",
      "8896/9200 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9794\n",
      " *** ROC AUC Score: 0.9977542324081539 - roc-auc_val: 0.9908081062525623 ***\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98000 to 0.98087, saving model to ./model-weights.03-0.980870.hdf5\n",
      "9200/9200 [==============================] - 1s 132us/sample - loss: 0.0602 - acc: 0.9797 - val_loss: 0.0739 - val_acc: 0.9809\n",
      "Epoch 4/20\n",
      "8384/9200 [==========================>...] - ETA: 0s - loss: 0.0480 - acc: 0.9833\n",
      " *** ROC AUC Score: 0.9987938200726387 - roc-auc_val: 0.9887533895416896 ***\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98087\n",
      "9200/9200 [==============================] - 1s 124us/sample - loss: 0.0467 - acc: 0.9837 - val_loss: 0.0854 - val_acc: 0.9791\n",
      "Epoch 5/20\n",
      "9024/9200 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9846\n",
      " *** ROC AUC Score: 0.9993044680267521 - roc-auc_val: 0.9933320491353891 ***\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98087\n",
      "9200/9200 [==============================] - 1s 129us/sample - loss: 0.0420 - acc: 0.9847 - val_loss: 0.0641 - val_acc: 0.9809\n",
      "Epoch 6/20\n",
      "9184/9200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9850\n",
      " *** ROC AUC Score: 0.9992398346811106 - roc-auc_val: 0.9964931517675009 ***\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98087\n",
      "9200/9200 [==============================] - 1s 117us/sample - loss: 0.0424 - acc: 0.9850 - val_loss: 0.0589 - val_acc: 0.9809\n",
      "Epoch 7/20\n",
      "8704/9200 [===========================>..] - ETA: 0s - loss: 0.0305 - acc: 0.9894\n",
      " *** ROC AUC Score: 0.9996589496480265 - roc-auc_val: 0.9958806881325292 ***\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98087\n",
      "9200/9200 [==============================] - 1s 123us/sample - loss: 0.0300 - acc: 0.9898 - val_loss: 0.0636 - val_acc: 0.9809\n",
      "Epoch 8/20\n",
      "8928/9200 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9899\n",
      " *** ROC AUC Score: 0.9997036958103938 - roc-auc_val: 0.9970364662823952 ***\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98087 to 0.98174, saving model to ./model-weights.08-0.981739.hdf5\n",
      "9200/9200 [==============================] - 1s 132us/sample - loss: 0.0278 - acc: 0.9899 - val_loss: 0.0645 - val_acc: 0.9817\n",
      "Epoch 9/20\n",
      "8512/9200 [==========================>...] - ETA: 0s - loss: 0.0245 - acc: 0.9913\n",
      " *** ROC AUC Score: 0.9996475219382346 - roc-auc_val: 0.9925961049288505 ***\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98174 to 0.98522, saving model to ./model-weights.09-0.985217.hdf5\n",
      "9200/9200 [==============================] - 1s 141us/sample - loss: 0.0249 - acc: 0.9910 - val_loss: 0.0644 - val_acc: 0.9852\n",
      "Epoch 10/20\n",
      "9024/9200 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9934\n",
      " *** ROC AUC Score: 0.9998995994068276 - roc-auc_val: 0.995534942532142 ***\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 125us/sample - loss: 0.0180 - acc: 0.9935 - val_loss: 0.0687 - val_acc: 0.9852\n",
      "Epoch 11/20\n",
      "8960/9200 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9920\n",
      " *** ROC AUC Score: 0.9997761207763481 - roc-auc_val: 0.9956139700979448 ***\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 124us/sample - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0633 - val_acc: 0.9826\n",
      "Epoch 12/20\n",
      "9184/9200 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9926\n",
      " *** ROC AUC Score: 0.9998117396120634 - roc-auc_val: 0.9920280942996429 ***\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 129us/sample - loss: 0.0208 - acc: 0.9926 - val_loss: 0.0740 - val_acc: 0.9800\n",
      "Epoch 13/20\n",
      "8736/9200 [===========================>..] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      " *** ROC AUC Score: 0.9998998220245509 - roc-auc_val: 0.9965178478818142 ***\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 132us/sample - loss: 0.0178 - acc: 0.9943 - val_loss: 0.0584 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "9088/9200 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9952\n",
      " *** ROC AUC Score: 0.9998290295885668 - roc-auc_val: 0.9917638458764897 ***\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 117us/sample - loss: 0.0169 - acc: 0.9951 - val_loss: 0.0734 - val_acc: 0.9835\n",
      "Epoch 15/20\n",
      "8736/9200 [===========================>..] - ETA: 0s - loss: 0.0148 - acc: 0.9955\n",
      " *** ROC AUC Score: 0.9999679430478563 - roc-auc_val: 0.9974044383856644 ***\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 116us/sample - loss: 0.0144 - acc: 0.9958 - val_loss: 0.0708 - val_acc: 0.9817\n",
      "Epoch 16/20\n",
      "8544/9200 [==========================>...] - ETA: 0s - loss: 0.0114 - acc: 0.9964\n",
      " *** ROC AUC Score: 0.999895518081902 - roc-auc_val: 0.9957275722237863 ***\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 117us/sample - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0586 - val_acc: 0.9852\n",
      "Epoch 17/20\n",
      "9152/9200 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9956\n",
      " *** ROC AUC Score: 0.9998272486467811 - roc-auc_val: 0.992907275969199 ***\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 115us/sample - loss: 0.0146 - acc: 0.9957 - val_loss: 0.1064 - val_acc: 0.9765\n",
      "Epoch 18/20\n",
      "9088/9200 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9946\n",
      " *** ROC AUC Score: 0.9998814931653391 - roc-auc_val: 0.9971303115167859 ***\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 121us/sample - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0676 - val_acc: 0.9826\n",
      "Epoch 19/20\n",
      "9088/9200 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9953\n",
      " *** ROC AUC Score: 0.9998024638735958 - roc-auc_val: 0.9877062742948025 ***\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 117us/sample - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0998 - val_acc: 0.9826\n",
      "Epoch 20/20\n",
      "8416/9200 [==========================>...] - ETA: 0s - loss: 0.0100 - acc: 0.9971\n",
      " *** ROC AUC Score: 0.9997908877519883 - roc-auc_val: 0.9956831192180222 ***\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98522\n",
      "9200/9200 [==============================] - 1s 125us/sample - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0899 - val_acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b5de5eba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = data['train_X'].shape[1]   # 열 개수 \n",
    "model = build_network(input_features=input_features)\n",
    "model.fit(x=data['train_X'], y=data['train_y'], batch_size=32, epochs=20, verbose=1,\n",
    "         validation_data=(data['val_X'], data['val_y']), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaa084",
   "metadata": {},
   "source": [
    "### 정밀도, 재현율 및 f1 점수 측정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0704b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_from_prob(x, operating_point=0.5):\n",
    "    x[x >= operating_point] = 1 \n",
    "    x[x < operating_point] = 0 \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd966560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       933\n",
      "           1       0.91      0.95      0.93       217\n",
      "\n",
      "    accuracy                           0.97      1150\n",
      "   macro avg       0.95      0.97      0.96      1150\n",
      "weighted avg       0.97      0.97      0.97      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_val = model.predict(data['val_X'])\n",
    "y_hat_val = class_from_prob(y_prob_val)\n",
    "\n",
    "print(classification_report(data['val_y'], y_hat_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f809e08",
   "metadata": {},
   "source": [
    "### 텐서보드 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "629384b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.8.0 at http://localhost:6008/ (Press CTRL+C to quit)\n",
      "W0221 21:13:07.305130 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:07.305858 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:07.316735 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:07.317669 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:07.329047 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:07.329601 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:07.341012 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:07.341325 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:10.352617 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:10.352917 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:10.930545 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:10.931000 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:10.934991 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:10.935349 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:10.939385 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:10.939762 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0221 21:13:10.946392 140413237593856 plugin_event_accumulator.py:319] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0221 21:13:10.946663 140413237593856 plugin_event_accumulator.py:331] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./ch4_tb_log/ --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26c12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
